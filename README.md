# Pdf-Intelligent-Chat-With-History

An intelligent conversational RAG (Retrieval-Augmented Generation) chatbot that allows users to upload PDF files and ask questions based on their content. The system uses Groqâ€™s LLaMA 3.1 model, LangChain retrievers, Chroma vector storage, and Streamlit UI to provide accurate, context-aware answers with chat history support.

---

## ğŸš€ Features

### ğŸ“„ PDF Question Answering
- Upload single or multiple PDF files  
- Extract text using `PyPDFLoader`  
- Split documents into chunks with `RecursiveCharacterTextSplitter`  
- Generate embeddings using `HuggingFaceEmbeddings` (MiniLM-L6-v2)  
- Store and retrieve chunks via **ChromaDB**

### ğŸ’¬ Conversational RAG
- Maintains session-based chat history  
- Reformulates user queries based on chat context  
- Retrieves the most relevant content chunks  
- Generates concise answers (max 3 sentences)

### âš¡ Powered by Groq
Fast and efficient inference with:
ChatGroq(model_name="llama-3.1-8b-instant")

markdown
Copy code

### ğŸ§  Chat History Memory
Uses:
- `ChatMessageHistory`
- `RunnableWithMessageHistory`

Each session uses a unique `session_id`.

### ğŸ–¥ Streamlit User Interface
- Enter Groq API key  
- Upload PDFs  
- Provide session ID  
- Ask questions  
- View responses and stored chat history  

---

## ğŸ“‚ Project Structure

project-root/
â”‚â”€â”€ app.py # Main application file
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ .env # Environment variables (ignored by Git)
â”‚â”€â”€ .gitignore # Ignore rules
â”‚â”€â”€ README.md # Project documentation
â””â”€â”€ temp.pdf # Temporary file used internally

yaml
Copy code

---

## ğŸ” Environment Variables

Create a `.env` file in your project folder with:

GROQ_API_KEY=your_groq_api_key
HF_TOKKEN=your_huggingface_token # optional, matches your code variable name

yaml
Copy code

---

## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/vikrant-honbute/Pdf-Intelligent-Chat-With-History.git
cd Pdf-Intelligent-Chat-With-History
2ï¸âƒ£ Create Virtual Environment
bash
Copy code
python -m venv venv
venv\Scripts\activate   # Windows
3ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Run the Application
bash
Copy code
streamlit run app.py
Then open the local URL shown in the terminal.

ğŸ§© How It Works
User uploads PDFs

Text is loaded and split into overlapping chunks

Embeddings are generated and stored in Chroma

User enters a query

A history-aware retriever reformulates the question

Relevant chunks are retrieved

Groq LLM generates the answer

Chat history is stored per session

ğŸ’¡ Tech Stack
Component	Technology
UI	Streamlit
LLM	Groq â€“ LLaMA 3.1 (8B Instant)
Framework	LangChain
Vector Store	Chroma
Embeddings	HuggingFace MiniLM L6-v2
PDF Loader	PyPDFLoader
Memory	ChatMessageHistory

ğŸ¤ Contributing
Contributions and suggestions are welcome!

ğŸ“œ License
This project is licensed under the MIT License.

â­ Support
If you like this project, please â­ star the repository!

yaml
Copy code

---

If you want a **more stylish version with badges, emojis, centered title, or screenshots**, tell me â€” I can generate
